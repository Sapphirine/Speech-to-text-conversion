{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import librosa\n",
    "import os\n",
    "import time\n",
    "import h5py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['beach' 'bus' 'cafe/restaurant' 'car' 'city_center' 'forest_path'\n",
      " 'grocery_store' 'home' 'library' 'metro_station' 'office' 'park'\n",
      " 'residential_area' 'train' 'tram']\n"
     ]
    }
   ],
   "source": [
    "dir_path = 'ALL_data/AED_data'  # directory path\n",
    "\n",
    "# load all event types\n",
    "all_event = np.load(dir_path+'/event_types.npy')\n",
    "print(all_event)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = np.load(dir_path+'/train_labels.npy')\n",
    "print(train_label[0])  # (label, audio_file) pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# walk through the directory, find the files with .wav extension\n",
    "wav_files = []\n",
    "for (dirpath, dirnames, filenames) in os.walk(dir_path):\n",
    "    for file in filenames:\n",
    "        if '.wav' in file:\n",
    "            wav_files.append(file)\n",
    "        \n",
    "num_data = len(wav_files)\n",
    "\n",
    "val_label = np.load(dir_path+'/validation_labels.npy')\n",
    "test_label = np.load(dir_path+'/test_labels.npy')\n",
    "\n",
    "train_audio = []\n",
    "val_audio = []\n",
    "test_audio = []\n",
    "train_target = []\n",
    "val_target = []\n",
    "test_target = []\n",
    "\n",
    "for i in range(len(train_label)):\n",
    "    y, _ = librosa.load(dir_path+'/audio/'+train_label[i][1], sr=16000)\n",
    "    train_audio.append(y[:16000*10])\n",
    "    train_target.append(np.argmax((train_label[i][0] == np.array(all_event)).astype(np.float32)))\n",
    "\n",
    "for i in range(len(val_label)):\n",
    "    y, _ = librosa.load(dir_path+'/audio/'+val_label[i][1], sr=16000)\n",
    "    val_audio.append(y[:16000*10]) \n",
    "    val_target.append(np.argmax((val_label[i][0] == np.array(all_event)).astype(np.float32)))\n",
    "    \n",
    "for i in range(len(test_label)):\n",
    "    y, _ = librosa.load(dir_path+'/audio/'+test_label[i][1], sr=16000)\n",
    "    test_audio.append(y[:16000*10])\n",
    "    test_target.append(np.argmax((test_label[i][0] == np.array(all_event)).astype(np.float32)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AlexNet(nn.Module):\n",
    "    def __init__(self, num_classes=15):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=11, stride=4, padding=2),  # number of input channel is 1 (for image it is 3) \n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(16, 32, kernel_size=5, padding=2),  # we make the number of hidden channels smaller in these layers\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((3, 3))  # perform adaptive mean pooling on any size of the input to match the provided size\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(64 * 3 * 3, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)  # the dimension after adaptive average pooling is (batch, 64, 3, 3)\n",
    "        x = torch.flatten(x, 1)  # average\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "    \n",
    "# test it with a sample input\n",
    "model = AlexNet()\n",
    "sample_input = torch.randn(2, 1, 257, 626)  # (batch_size, num_channel, freq_dim, time_step)\n",
    "sample_output = model(sample_input)\n",
    "print(sample_output.shape)  # (batch_size, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "batch_size = 8\n",
    "\n",
    "class dataset_pipeline(Dataset):\n",
    "    def __init__(self, data, label):\n",
    "        super(dataset_pipeline, self).__init__()\n",
    "        \n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        \n",
    "        self._len = len(self.data)  # number of utterances\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # calculate STFT here\n",
    "        spec = librosa.stft(self.data[index].astype(np.float32), n_fft=512, hop_length=256)\n",
    "        label = self.label[index]\n",
    "        spec = torch.from_numpy(np.abs(spec))  # only use the magnitude spectrogram\n",
    "        label = torch.from_numpy(np.array(label)).long()\n",
    "            \n",
    "        return spec, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self._len\n",
    "    \n",
    "# define data loaders\n",
    "train_loader = DataLoader(dataset_pipeline(train_audio, train_target), \n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=True,\n",
    "                         )\n",
    "\n",
    "validation_loader = DataLoader(dataset_pipeline(val_audio, val_target), \n",
    "                               batch_size=batch_size, \n",
    "                               shuffle=False,\n",
    "                              )\n",
    "\n",
    "dataset_len = len(train_loader)\n",
    "log_step = dataset_len // 4\n",
    "\n",
    "# CE loss\n",
    "def CE(output, target):\n",
    "    # output shape: (batch, num_classes)\n",
    "    # target shape: (batch,)\n",
    "    \n",
    "    loss = nn.CrossEntropyLoss()\n",
    "    \n",
    "    return loss(output, target)\n",
    "\n",
    "\n",
    "def train(model, epoch, versatile=True):\n",
    "    start_time = time.time()\n",
    "    model = model.train()  # set the model to training mode. Always do this before you start training!\n",
    "    train_loss = 0.\n",
    "    \n",
    "    # load batch data\n",
    "    for batch_idx, data in enumerate(train_loader):\n",
    "        spec, label = data\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(spec.unsqueeze(1))\n",
    "        \n",
    "        # CE as objective\n",
    "        loss = CE(output, label)\n",
    "        \n",
    "        # automatically calculate the backward pass\n",
    "        loss.backward()\n",
    "        # perform the actual backpropagation\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.data.item()\n",
    "        \n",
    "        # OPTIONAL: you can print the training progress \n",
    "        if versatile:\n",
    "            if (batch_idx+1) % log_step == 0:\n",
    "                elapsed = time.time() - start_time\n",
    "                print('| epoch {:3d} | {:5d}/{:5d} batches | ms/batch {:5.2f} | CE {:5.4f} |'.format(\n",
    "                    epoch, batch_idx+1, len(train_loader),\n",
    "                    elapsed * 1000 / (batch_idx+1), \n",
    "                    train_loss / (batch_idx+1)\n",
    "                    ))\n",
    "    \n",
    "    train_loss /= (batch_idx+1)\n",
    "    print('-' * 99)\n",
    "    print('    | end of training epoch {:3d} | time: {:5.2f}s | CE {:5.4f} |'.format(\n",
    "            epoch, (time.time() - start_time), train_loss))\n",
    "    \n",
    "    return train_loss\n",
    "        \n",
    "def validate(model, epoch):\n",
    "    start_time = time.time()\n",
    "    model = model.eval()  # set the model to evaluation mode. Always do this during validation or test phase!\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # load batch data\n",
    "    for batch_idx, data in enumerate(validation_loader):\n",
    "        spec, label = data\n",
    "        \n",
    "        # you don't need to calculate the backward pass and the gradients during validation\n",
    "        # so you can call torch.no_grad() to only calculate the forward pass to save time and memory\n",
    "        with torch.no_grad():\n",
    "        \n",
    "            output = model(spec.unsqueeze(1))\n",
    "        \n",
    "            # calculate accuracy\n",
    "            _, output_label = torch.max(output, 1)\n",
    "            output_label = output_label.data.numpy()\n",
    "            label = label.data.numpy()\n",
    "            correct += np.sum(output_label == label)\n",
    "            total += len(label)\n",
    "        \n",
    "    accuracy = correct / total\n",
    "    print('    | end of validation epoch {:3d} | time: {:5.2f}s | Accuracy {:5.4f} |'.format(\n",
    "            epoch, (time.time() - start_time), accuracy))\n",
    "    print('-' * 99)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "\n",
    "total_epoch = 100  # train the model for 100 epochs\n",
    "model_save = 'best_AlexNet.pt'  # path to save the best validation model\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# main function\n",
    "\n",
    "training_loss = []\n",
    "validation_loss = []\n",
    "\n",
    "for epoch in range(1, total_epoch + 1):\n",
    "    training_loss.append(train(model, epoch))\n",
    "    validation_loss.append(validate(model, epoch))\n",
    "    \n",
    "    if training_loss[-1] == np.min(training_loss):\n",
    "        print('      Best training model found.')\n",
    "    if validation_loss[-1] == np.max(validation_loss):\n",
    "        # save current best model on validation set\n",
    "        with open(model_save, 'wb') as f:\n",
    "            torch.save(model.state_dict(), f)\n",
    "            print('      Best validation model found and saved.')\n",
    "    \n",
    "    print('-' * 99)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('best_AlexNet.pt'))\n",
    "model.eval()\n",
    "\n",
    "correct = []\n",
    "total = len(test_audio)\n",
    "\n",
    "for i in range(len(test_audio)):\n",
    "    this_spec = librosa.stft(test_audio[i].astype(np.float32), n_fft=512, hop_length=256)\n",
    "    this_label = test_target[i]\n",
    "    spec = torch.from_numpy(np.abs(this_spec))  # only use the magnitude spectrogram\n",
    "    this_label = torch.from_numpy(np.array(this_label)).long()\n",
    "    \n",
    "    output = model(spec.unsqueeze(0).unsqueeze(1))\n",
    "        \n",
    "    # calculate accuracy\n",
    "    _, output_label = torch.max(output, 1)\n",
    "    output_label = output_label.data.numpy()\n",
    "    this_label = this_label.data.numpy()\n",
    "    correct.append(np.sum(output_label == this_label))\n",
    "\n",
    "print('Overall accuracy: {:.2f}%'.format(np.sum(correct) / total * 100))\n",
    "\n",
    "# accuracy for each class\n",
    "for i in range(len(test_audio) // 2):\n",
    "    print('Accuracy for {:s}: {:.2f}%'.format(all_event[i], np.sum(correct[i*2:i*2+2]) / 2 * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
